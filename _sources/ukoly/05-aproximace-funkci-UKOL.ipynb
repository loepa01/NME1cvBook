{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(ukol4)=\n",
    "# Zápočtový úkol 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"margin-top: 25px; margin-bottom: 25px; padding-top: 0px; padding-bottom: 0px; padding-left: 0px; padding-right: 0px; border-radius: 4px; border-color: #E0B32C; border-right-width: 1px; border-top-width: 1px; border-bottom-width: 1px; border-left-width: 3px; border-style: solid\">\n",
    "<div style=\"background: #FFF3CD; color: #000000; padding-left: 20px; padding-top: 10px; padding-bottom: 10px; border-radius: 1px 3px 0px 0px; font-weight: 600\">Úkol</div>\n",
    "<div style=\"padding-left: 20px; padding-right: 20px; padding-top: 0px; padding-bottom: 0px; border-radius: 0px 0px 3px 3px\">\n",
    "<p>\n",
    "\n",
    "Uvažujte následující situaci. Provádíte experiment a naměříte sadu dat. Bohužel jste ale ztratili vaše teoretické poznámky k experimentu a již nevíte, jakým zákonem/vzorečkem se data řídí. Nedokážete již tedy proložit data odpovídající modelovou funkcí a získat parametry tohoto modelu. Přesto nezačnete zoufat a tuto patálii vyřešíte pomocí numerických nástrojů na počítači. Záchranou je pro vás, že jste si zapamatovali, že se data řídí polynomiální závislostí. Již ale neznáte přesný stupeň onoho polynomu.\n",
    "\n",
    "Definice úlohy:\n",
    "Uvažujte $N=100$ dvojic $(x_i, y_i)$ tvořící experimentální data. Data získáte pomocí funkce `(xdata, ydata) = proved_experiment()` (implementované v binárním souboru `experiment.pyc`), která volí náhodný stupeň polynomu $m \\in [0,10]$, pro který vygeneruje odpovídající náhodná data s přidaným gausovským šumem (podle normálního rozdělení). Funkce vrací dva vektory/pole $\\vec{x}$ a $\\vec{y}$. S každým novým voláním této funkce jsou vygenerována data pro jiný modelový polynom!\n",
    "\n",
    "1. Vygenerujte experimentální data pomocí připravené funkce `proved_experiment()`.\n",
    "\n",
    "2. Rozdělte data na *trénovací* a *testovací* v poměru 3:1 (testovacích dat je třeba méně). Rozdělte data do skupin náhodně tak, aby jste výběrem nezanesli nechtěnou informaci do testovací množiny a aby byly data přibližně rovnoměrně rozprostřeny v celém intervalu v obou skupinách! To zajistí přesnější ohodnocení natrénovaného modelu.\n",
    "\n",
    "3. Natrénujte/spočítejte parametry modelu s využitím *trénovacích dat*.\n",
    "\n",
    "4. Aplikujte model na *testovací data* a spočítejte chybu, které se model na těchto datech dopouští - účelová funkce $S$ (viz cvičení).\n",
    "\n",
    "5. Opakujte kroky 3. a 4. pro různé stupně polynomu a na základě chyby testovacích dat určete parametry a ideální stupeň polynomu modelu.\n",
    "\n",
    "Cílem je pro libovolné zavolání funkce experimentu najít ideální model, který odpovídá datům nejlépe. Funkce `proved_experiment()` je již importována v připravené buňce v tomto notebooku, stačí ji zavolat. Pokud chcete řešit úlohu lokálně na osobním počítači, je třeba si spolu s notebookem stáhnout soubor `experiment.pyc` ze složky `ukoly/`.\n",
    "\n",
    "Vykreslete závislost testovací chyby na stupni modelového polynomu. Vykreslete vygenerované data a funkci optimálního modelu.\n",
    "\n",
    "Můžete pozorovat, že v některých případech vychází stupeň polynomu nečekaně vysoký! To je způsobeno tím, že ohodnocení modelů není vždy optimální (viz Bonus a následující poznámky). Přesto výsledek není úplně špatně, jelikož koeficienty u členů vysokého řádu jsou velmi malé. A při jiném výběru testovací množiny již může vyjít správný stupeň polynomu, kterému odpovídají naměřená data. Zkuste proto spustit výběr a trénování několikrát a vyhodnotit správný stupeň polynomu. **Nebo se podívejte na Bonus.**\n",
    "\n",
    "*Bonus:*\n",
    "\n",
    "Upravte krok 2. tak, že místo jednoduché validace použijete pokročilejší [křížovou validaci](https://cs.wikipedia.org/wiki/K%C5%99%C3%AD%C5%BEov%C3%A1_validace) (cross validation). Použijte například [k-fold křížovou validaci](https://en.wikipedia.org/wiki/Cross-validation_(statistics)#k-fold_cross-validation) (viz následující poznámky). Tato metoda poskytuje efektivnější ohodnocení modelu.\n",
    "</p>\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"margin-top: 25px; margin-bottom: 25px; padding-top: 0px; padding-bottom: 0px; padding-left: 0px; padding-right: 0px; border-radius: 4px; border-color: #276BE9; border-right-width: 1px; border-top-width: 1px; border-bottom-width: 1px; border-left-width: 3px; border-style: solid\">\n",
    "<div style=\"background: #DCE7FC; color: #000000; padding-left: 20px; padding-top: 10px; padding-bottom: 10px; border-radius: 1px 3px 0px 0px; font-weight: 600\">Poznámka</div>\n",
    "<div style=\"padding-left: 20px; padding-right: 20px; padding-top: 0px; padding-bottom: 0px; border-radius: 0px 0px 3px 3px\">\n",
    "<p>\n",
    "\n",
    "**Validace** - rozdělení dat na trénovací a testovací části - se běžně používá při modelování dat. Je to základní nástroj pro ohodnocení například neuronových sítí, které představují obecné zobrazené mezi vstupními parametry (`xdata`) a daty (`ydata`).\n",
    "\n",
    "Princip spočívá v balacování mezi přetrénováním (oversampling) a podtrénováním (undersampling - bias). Tato myšlenka se také nazývá [bias-variance tradeoff](https://en.wikipedia.org/wiki/Bias%E2%80%93variance_tradeoff). \n",
    "\n",
    "Když bychom volili větší a větší stupeň polynomu, podaří se nám nafitovat model datům čím dál přesněji. Pro volbu $m=N$ se dostáváme k interpolaci - fit bude procházet všemi data pointy přesně. Dopustíme se ale tzv. *přetrénování*, jelikož bude model v datech hledat více vlastností/stupnů volnosti/více křivosti než v nich je. Pak když použijeme model na predikování nových dat, bude příliž citlivý na šum v hodnotách $x$.\n",
    "\n",
    "Naopak pokud zvolíme příliž nízký stupeň polynomu, nebude model schopný zachytit podstatný charakter schovaný v datech a bude se dopouštět velké chyby z důvodu neznalosti (bias). Takový model není sice citlivý na šum, ale je zpočátku nepřesný.\n",
    "\n",
    "Díky využití části dat, na kterých model netrénujeme, lze model otestovat a získat hodnocení, jak si model vede na nových, předem neznámých datech. Když nalezneme minimum chyby na testovacích datech, dostaneme ideální tvar modelu.\n",
    "</p>\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Pouze k Bonusu:*\n",
    "\n",
    "<div style=\"margin-top: 25px; margin-bottom: 25px; padding-top: 0px; padding-bottom: 0px; padding-left: 0px; padding-right: 0px; border-radius: 4px; border-color: #276BE9; border-right-width: 1px; border-top-width: 1px; border-bottom-width: 1px; border-left-width: 3px; border-style: solid\">\n",
    "<div style=\"background: #DCE7FC; color: #000000; padding-left: 20px; padding-top: 10px; padding-bottom: 10px; border-radius: 1px 3px 0px 0px; font-weight: 600\">Poznámka</div>\n",
    "<div style=\"padding-left: 20px; padding-right: 20px; padding-top: 0px; padding-bottom: 0px; border-radius: 0px 0px 3px 3px\">\n",
    "<p>\n",
    "\n",
    "**Křížová validace** (cross-validation) je pokročilejší technika rozdělení dat na trénovací a testovací. I když rozdělujeme data náhodně do obou množin, každý výběr zanese do testovací množiny určitou informaci, která může ovlivnit ohodnocení modelů.\n",
    "\n",
    "Například můžeme uvažovat náhodný výběr testovací množiny, jejíž data pointy budou tvarově odpovídat určitému polynomu řádu $p$. Data se ve skutečnosti řídí polynomem menšího stupně $q < p$. Jelikož ale hodnotíme natrénovaný model pomocí testovací množiny blízké polynomu stupně $p$, bude modelový polynom stupně $p$ zvýhodněn oproti stupni $q$. A tedy můžeme získat nepřesný výsledný model.\n",
    "\n",
    "V opačném případě testovací množina nemusí zachytit určitou vlastnost, která se v datech skrývá. Uvažujme například polynom vysokého řádu $q$, kterému odpovídají naměřená data. Náhodně je vybrána testovací množina, která velmi řídce pokrývá část intervalu, kde polynom vysokého řádu prudce roste. Tím naopak chybí v testovací datech dostatek informace o datech a budou upřednostovány modelové polynomy nižšího řádu $p < q$, než je skutečný řád.\n",
    "\n",
    "V případě, kdy máme dostatek dat a rozdělujeme data náhodně, bude pro nás zásadní spíš první případ. Tedy *přetrénování* dat důsledkem neideálního výběru testovací množiny.\n",
    "\n",
    "Křížová validace se snaží potlačit zanesení testovací množiny tak, že provede výběr **opakovaně**. Způsobů opakovaného rozdělení dat na trénovací a testovací je [mnoho](https://en.wikipedia.org/wiki/Cross-validation_(statistics)#Types). Zde si popíšeme jeden z nejpoužívanějších.\n",
    "\n",
    "**K-fold cross-validation**\n",
    "\n",
    "O této metodě se podrobně můžete dočíst například [zde](https://www.datacamp.com/tutorial/k-fold-cross-validation), kde uvidíte i použití v praxi s využitím vhodných knihovních funkcí.\n",
    "\n",
    "Tato metoda slouží k nalezení vhodné volby tzv. **hyperparametrů** modelu. V našem případě je to stupeň modelového polynomu. Obecně to může být parametr ovlivňující řád nebo tvar modelu (hloubka neuronové sítě atd.).\n",
    "\n",
    "Kroky k-fold křížové validace jsou následující:\n",
    "\n",
    "1. Náhodně zamícháme data, aby nebyly seřazená podle hodnoty parametru (`xdata`) nebo jiného pravidla.\n",
    "2. Rozdělíme na $k$ podmožin a zvolíme hodnotu $p$ řádu modelového polynomu (hyperparameter).\n",
    "3. Provedeme trénování a otestování modelu $k$ krát tak, že testovací množinou bude vždy podmnožina $k$ a zbytek podmožin bude sloužit jako trénovací množina (viz následující obrázek).\n",
    "4. Jako finální ohodnocení modelu vezmeme průměr jednotlivých $k$ hodnocení z iterací křížové validace.\n",
    "\n",
    "Nakonec stačí již porovnat výsledná hodnocení pro modely různých řádů a určit optimální řád modelového polynomu, podle kterého se řídí naměřená data.\n",
    "\n",
    "Poslední krok je zjistit parametry modelu - koeficienty polynomu s optimálním řádem. Jelikož již nepotřebujeme model hodnotit, stačí natrénovat model onoho řádu znovu na všech datech. Díky křížové validaci známe přesně řád polynomu a nemůžeme se tedy v naší úloze již dopustit *přetrénování*. Každý další data point již jen zpřesňuje znalost parametrů modelu. Pokud bychom chtěli znát míru přesnosti výsledného modelu, je třeba využít testovacích dat.\n",
    "\n",
    "<div>\n",
    "<img src=\"../images/cross-validace.png\" width=\"500\"/>\n",
    "</div>\n",
    "\n",
    "Tímto způsobem je každý data point použit právě jednou na trénování a testování jednoho z modelů. Opakovaným výběrem zajistíme objektivnější hodnocení modelu a tím zpřesníme výběr nejlepšího modelu, kterému by data měla odpovídat.\n",
    "</p>\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import funkce experimentu:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* JupyterHub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from experiment import proved_experiment\n",
    "\n",
    "def proved_experiment_JupyterHub():\n",
    "    return proved_experiment()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Windows a Linux:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "def proved_experiment_Windows():\n",
    "    # USE THIS FUNCTION FOR WINDOWS\n",
    "    # returns xdata, ydata\n",
    "    \n",
    "    subprocess.run([\"experiment.exe\"], capture_output=True) # zavolani binarniho souboru experiment.exe - ten ulozi vygenerovana data do experimentData.npy\n",
    "    data = np.load('experimentData.npy') # nacteni vygenerovanych dat\n",
    "    return data[0, :], data[1, :]\n",
    "\n",
    "\n",
    "def proved_experiment_Linux():\n",
    "    # USE THIS FUNCTION FOR LINUX\n",
    "    # returns xdata, ydata\n",
    "    \n",
    "    subprocess.run([\"./experiment\"], capture_output=True) # zavolani binarniho souboru experiment.exe - ten ulozi vygenerovana data do experimentData.npy\n",
    "    data = np.load('experimentData.npy') # nacteni vygenerovanych dat\n",
    "    return data[0, :], data[1, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otestování funkčnosti generování dat. Měla by fungovat právě jedna z následujících možností podle toho, v jakém operačním systému pracujete:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* JupyterHub - použijte `proved_experiment_JupyterHub()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xdata, ydata = proved_experiment_JupyterHub()\n",
    "plt.scatter(xdata, ydata);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Windows - použijte `proved_experiment_Windows()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xdata, ydata = proved_experiment_Windows()\n",
    "plt.scatter(xdata, ydata);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Linux/JupyterHub - použijte `proved_experiment_Linux()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xdata, ydata = proved_experiment_Linux()\n",
    "plt.scatter(xdata, ydata);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Řešení úlohy:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Vygenerování dat**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## DOPLŇTE ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Rozdělení na trénovací a testovací množinu**\n",
    "\n",
    "\n",
    "<div style=\"margin-top: 25px; margin-bottom: 25px; padding-top: 0px; padding-bottom: 0px; padding-left: 0px; padding-right: 0px; border-radius: 4px; border-color: #00843F; border-right-width: 1px; border-top-width: 1px; border-bottom-width: 1px; border-left-width: 3px; border-style: solid\">\n",
    "<div style=\"background: #D6ECE1; color: #000000; padding-left: 20px; padding-top: 10px; padding-bottom: 10px; border-radius: 1px 3px 0px 0px; font-weight: 600\">Tip</div>\n",
    "<div style=\"padding-left: 20px; padding-right: 20px; padding-top: 0px; padding-bottom: 0px; border-radius: 0px 0px 3px 3px\">\n",
    "<p>\n",
    "\n",
    "Pro rozdělení dat na trénovací a testovací množinu můžete použít tyto dvě možnosti:\n",
    "\n",
    "1. Metodu [`train_test_split()`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) z knihovny `sklearn.model_selection`, která automaticky při výběru náhodně zamíchá data.\n",
    "2. Kombinaci funkcí [`np.random.choice()`](https://numpy.org/doc/2.1/reference/random/generated/numpy.random.choice.html) a [`np.setdiff1d()`](https://numpy.org/doc/2.2/reference/generated/numpy.setdiff1d.html) pro výběr indexů prvků do odpovídajících množin.\n",
    "3. Pro *křížovou validaci* lze použít například třídu [`KFold`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html) z knihovny `sklearn.model_selection`. Funkce `split()` zavolaná na instanci třídy `KFold` vrátí seznam $k$ dvojic indexů prvků z trénovací a testovací množiny (viz příklad v dokumentaci třídy).\n",
    "</p>\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## DOPLŇTE ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Trénování a testování modelu na datech pro různé stupně polynomu**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## DOPLŇTE ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Výběr nejlepšího modelu a stupně modelového polynomu + vizualizace výsledku**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## DOPLŇTE ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
